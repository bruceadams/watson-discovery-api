/* 
 * Discovery
 *
 * The IBM Watson&trade; Discovery Service is a cognitive search and content analytics engine that you can add to applications to identify patterns, trends and actionable insights to drive better decision-making. Securely unify structured and unstructured data with pre-enriched content, and use a simplified query language to eliminate the need for manual filtering of results.
 *
 * OpenAPI spec version: 1.0
 * 
 * Generated by: https://openapi-generator.tech
 */

/// TokenDictRule : An object defining a single tokenizaion rule.

#[allow(unused_imports)]
use serde_json::Value;

#[derive(Debug, Serialize, Deserialize)]
pub struct TokenDictRule {
  /// The string to tokenize.
  #[serde(rename = "text")]
  text: String,
  /// Array of tokens that the `text` field is split into when found.
  #[serde(rename = "tokens")]
  tokens: Vec<String>,
  /// Array of tokens that represent the content of the `text` field in an alternate character set.
  #[serde(rename = "readings")]
  readings: Option<Vec<String>>,
  /// The part of speech that the `text` string belongs to. For example `noun`. Custom parts of speech can be specified.
  #[serde(rename = "part_of_speech")]
  part_of_speech: String
}

impl TokenDictRule {
  /// An object defining a single tokenizaion rule.
  pub fn new(text: String, tokens: Vec<String>, part_of_speech: String) -> TokenDictRule {
    TokenDictRule {
      text: text,
      tokens: tokens,
      readings: None,
      part_of_speech: part_of_speech
    }
  }

  pub fn set_text(&mut self, text: String) {
    self.text = text;
  }

  pub fn with_text(mut self, text: String) -> TokenDictRule {
    self.text = text;
    self
  }

  pub fn text(&self) -> &String {
    &self.text
  }


  pub fn set_tokens(&mut self, tokens: Vec<String>) {
    self.tokens = tokens;
  }

  pub fn with_tokens(mut self, tokens: Vec<String>) -> TokenDictRule {
    self.tokens = tokens;
    self
  }

  pub fn tokens(&self) -> &Vec<String> {
    &self.tokens
  }


  pub fn set_readings(&mut self, readings: Vec<String>) {
    self.readings = Some(readings);
  }

  pub fn with_readings(mut self, readings: Vec<String>) -> TokenDictRule {
    self.readings = Some(readings);
    self
  }

  pub fn readings(&self) -> Option<&Vec<String>> {
    self.readings.as_ref()
  }

  pub fn reset_readings(&mut self) {
    self.readings = None;
  }

  pub fn set_part_of_speech(&mut self, part_of_speech: String) {
    self.part_of_speech = part_of_speech;
  }

  pub fn with_part_of_speech(mut self, part_of_speech: String) -> TokenDictRule {
    self.part_of_speech = part_of_speech;
    self
  }

  pub fn part_of_speech(&self) -> &String {
    &self.part_of_speech
  }


}



